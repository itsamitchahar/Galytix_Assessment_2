{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1osqH6TApx-ZbF2tAuq0FpNeOEfyF4o55","timestamp":1699265538447}],"gpuType":"T4","authorship_tag":"ABX9TyMlm1isVEDCV//dgSrNFUs8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive',force_remount=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pp9Bi9Yn6vUI","executionInfo":{"status":"ok","timestamp":1699262198304,"user_tz":-330,"elapsed":24496,"user":{"displayName":"Amit Chahar","userId":"12717660797249929299"}},"outputId":"2d8d53db-089c-4586-8344-2c2034090f00"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["import gensim\n","from gensim.models import KeyedVectors\n","\n","# Load pretrained Word2Vec vectors from the binary file\n","location = '/content/gdrive/MyDrive/GoogleNews-vectors-negative300.bin'\n","wv = KeyedVectors.load_word2vec_format(location, binary=True, limit=1000000)\n","\n","# Save the vectors as a flat file\n","wv.save_word2vec_format('vectors.csv')"],"metadata":{"id":"kdyUDBMO67ii","executionInfo":{"status":"ok","timestamp":1699262657000,"user_tz":-330,"elapsed":210495,"user":{"displayName":"Amit Chahar","userId":"12717660797249929299"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from scipy.spatial.distance import cosine\n","from gensim.models import KeyedVectors\n","\n","# Define a function to calculate the phrase vector\n","def phrase_vector(phrase, word_vectors):\n","    words = phrase.split()\n","    word_vecs = [word_vectors[word] for word in words if word in word_vectors]\n","    if not word_vecs:\n","        return np.zeros(300)  # Assuming the vectors are 300-dimensional\n","    return np.mean(word_vecs, axis=0)\n","\n","# Define a function to calculate distance between two phrases\n","def phrase_distance(phrase1, phrase2, word_vectors, use_cosine=True):\n","    vec1 = phrase_vector(phrase1, word_vectors)\n","    vec2 = phrase_vector(phrase2, word_vectors)\n","    return cosine(vec1, vec2) if use_cosine else np.linalg.norm(vec1 - vec2)\n","\n","# For on-the-fly execution\n","def find_closest_match(input_phrase, phrases, word_vectors):\n","    min_distance = float('inf')\n","    closest_phrase = None\n","    for phrase in phrases:\n","        distance = phrase_distance(input_phrase, phrase, word_vectors)\n","        if distance < min_distance:\n","            min_distance = distance\n","            closest_phrase = phrase\n","    return closest_phrase, min_distance\n","\n","\n","word_vectors_path = 'vectors.csv'\n","\n","phrases_df = pd.read_csv('/content/gdrive/MyDrive/phrases.csv', encoding='latin-1')\n","phrases = phrases_df['Phrases'].tolist()\n","\n","# Replace 'word_vectors_path' with the actual path to your Word2Vec vectors file\n","word_vectors_path = '/content/gdrive/MyDrive/GoogleNews-vectors-negative300.bin'\n","\n","# Load the Word2Vec vectors\n","word_vectors = KeyedVectors.load_word2vec_format(word_vectors_path, binary=True)\n","\n","\n","user_input = \"how company compares to its peers?\"\n","closest_phrase, distance = find_closest_match(user_input, phrases, word_vectors)\n","print(f\"The closest match is: '{closest_phrase}' with a distance of {distance}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uBajnViL8D2q","executionInfo":{"status":"ok","timestamp":1699264412242,"user_tz":-330,"elapsed":47343,"user":{"displayName":"Amit Chahar","userId":"12717660797249929299"}},"outputId":"8ef71937-aad9-4d67-ad33-ee97c651ba4d"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["The closest match is: 'how company compares to its peers?' with a distance of 0\n"]}]}]}